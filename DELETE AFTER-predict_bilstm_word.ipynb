{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELETE AFTER AND KEEP script predict_bilstm_word.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionaries\n",
    "with open('models/bilstm_word/id2word.pkl', 'rb') as f:\n",
    "    id2word = pickle.load(f)\n",
    "with open('models/bilstm_word/id2tag.pkl', 'rb') as f:\n",
    "    id2tag = pickle.load(f)\n",
    "with open('models/bilstm_word/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "with open('models/bilstm_word/nertags.pkl', 'rb') as f:\n",
    "    nertags = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (wordembed): Embedding(23626, 100)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bilstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, total_words, num_class):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.wordembed = nn.Embedding(total_words, embedding_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.bilstm = nn.LSTM(embedding_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(2 * hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x, xlengths):\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        word_embedding = self.wordembed(x)\n",
    "        word_embedding = self.dropout(word_embedding)\n",
    "\n",
    "        out, (h, c) = self.bilstm(word_embedding)\n",
    "        out = self.linear(out)\n",
    "        out = out.view(-1, out.shape[2])\n",
    "        out = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "# Initialize your model instance with the same architecture as the trained model\n",
    "model = BiLSTM(embedding_size=100, hidden_size=100, total_words=len(vocab), num_class=len(nertags))\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('models/bilstm_word/trained_bilstm_model_state_dict.pth'))\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordembed.weight torch.Size([23626, 100])\n",
      "bilstm.weight_ih_l0 torch.Size([400, 100])\n",
      "bilstm.weight_hh_l0 torch.Size([400, 100])\n",
      "bilstm.bias_ih_l0 torch.Size([400])\n",
      "bilstm.bias_hh_l0 torch.Size([400])\n",
      "bilstm.weight_ih_l0_reverse torch.Size([400, 100])\n",
      "bilstm.weight_hh_l0_reverse torch.Size([400, 100])\n",
      "bilstm.bias_ih_l0_reverse torch.Size([400])\n",
      "bilstm.bias_hh_l0_reverse torch.Size([400])\n",
      "linear.weight torch.Size([10, 200])\n",
      "linear.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "# Print the keys and shapes of the parameters in the state dictionary\n",
    "for key, value in state_dict.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_predictions(model, loader, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        with torch.no_grad():\n",
    "            for step, (X, Y, xlen) in enumerate(loader):\n",
    "                Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
    "                Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
    "                ypred = model(X.long().to(device), xlen.to(device))\n",
    "                ypred = torch.argmax(ypred.to('cpu'), dim=1)\n",
    "                ypred = ypred.view(Y.shape[0], -1)\n",
    "                for i in range(len(ypred)):\n",
    "                    for j in range(len(ypred[i])):\n",
    "                        word = id2word[int(X[i, j])]\n",
    "                        tag = id2tag[int(ypred[i, j])]\n",
    "                        f.write(f\"{word}\\t{tag}\\n\")\n",
    "                    f.write('\\n')\n",
    "\n",
    "# Assuming 'device' and 'id2word', 'id2tag' are defined elsewhere\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(datapath) as f:\n",
    "        lines = f.readlines()\n",
    "        sentence = []\n",
    "        tag = []\n",
    "        for line in lines:\n",
    "            line = line.strip()  \n",
    "            if line: \n",
    "                word, tag_label = line.split('\\t')\n",
    "                if vocab is not None:\n",
    "                    if word in vocab.keys():\n",
    "                        sentence.append(vocab[word])\n",
    "                    else:\n",
    "                        sentence.append(vocab['<oov>'])\n",
    "                if nertags is not None:\n",
    "                    tag.append(nertags[tag_label])\n",
    "            else:  \n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(tag)\n",
    "                    sentence = []\n",
    "                    tag = []\n",
    "\n",
    "    max_length = max(len(x) for x in sentences)\n",
    "    x_lengths = [len(x) for x in sentences]\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    for sent, tag in zip(sentences, tags):\n",
    "        length_to_append = max_length - len(sent)\n",
    "        X_test.append(sent + [0] * length_to_append)  \n",
    "        Y_test.append(tag + [0] * length_to_append) \n",
    "\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    Y_test = torch.Tensor(Y_test)\n",
    "    x_lengths = torch.Tensor(x_lengths)\n",
    "\n",
    "    return X_test, Y_test, x_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPAN-F1 SCORE\n",
    "\n",
    "def readBIO(path):\n",
    "    ents = []\n",
    "    curEnts = []\n",
    "    for line in open(path):\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            ents.append(curEnts)\n",
    "            curEnts = []\n",
    "        elif line[0] == '#' and len(line.split('\\t')) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            curEnts.append(line.split('\\t')[1])\n",
    "    return ents\n",
    "\n",
    "def toSpans(tags):\n",
    "    spans = set()\n",
    "    for beg in range(len(tags)):\n",
    "        if tags[beg][0] == 'B':\n",
    "            end = beg\n",
    "            for end in range(beg+1, len(tags)):\n",
    "                if tags[end][0] != 'I':\n",
    "                    break\n",
    "            spans.add(str(beg) + '-' + str(end) + ':' + tags[beg][2:])\n",
    "            #print(end-beg)\n",
    "    return spans\n",
    "\n",
    "def getInstanceScores(predPath, goldPath):\n",
    "    goldEnts = readBIO(goldPath)\n",
    "    predEnts = readBIO(predPath)\n",
    "    entScores = []\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for goldEnt, predEnt in zip(goldEnts, predEnts):\n",
    "        goldSpans = toSpans(goldEnt)\n",
    "        predSpans = toSpans(predEnt)\n",
    "        overlap = len(goldSpans.intersection(predSpans))\n",
    "        tp += overlap\n",
    "        fp += len(predSpans) - overlap\n",
    "        fn += len(goldSpans) - overlap\n",
    "        \n",
    "    prec = 0.0 if tp+fp == 0 else tp/(tp+fp)\n",
    "    rec = 0.0 if tp+fn == 0 else tp/(tp+fn)\n",
    "    f1 = 0.0 if prec+rec == 0.0 else 2 * (prec * rec) / (prec + rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_type = 'capitalization_swap'\n",
    "rate = 0.1\n",
    "\n",
    "testdatapath = f'data/altered/{noise_type}_rate_{rate}.txt'\n",
    "\n",
    "# Test dataset preparation\n",
    "Xtest, Ytest, x_testlengths = load_data(testdatapath)\n",
    "\n",
    "testdataset = TensorDataset(Xtest, Ytest, x_testlengths)\n",
    "loader_test = DataLoader(testdataset, batch_size=1, shuffle=False)\n",
    "prediction_path = f'predictions/bilstm_word/{noise_type}_rate_{rate}.txt'\n",
    "\n",
    "# Output predictions\n",
    "out_predictions(model, loader_test, prediction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-F1 score:  0.6900822626860154\n"
     ]
    }
   ],
   "source": [
    "span_f1_score = getInstanceScores(prediction_path,'data/gold.txt')\n",
    "print('Span-F1 score: ', span_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
