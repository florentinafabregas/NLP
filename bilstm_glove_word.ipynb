{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/HarmanDotpy/Named-Entity-Recognition-in-Pytorch/blob/main/scripts/train_bilstm_char_random_glove.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import io\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle as pickle\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import seqeval\n",
    "from seqeval.metrics import accuracy_score as seq_accuracy_score\n",
    "from seqeval.metrics import classification_report as seq_classification_report\n",
    "from seqeval.metrics import f1_score as seq_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BILSTM model\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.wordembed = nn.Embedding.from_pretrained(pretrained_embed, freeze = False)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.bilstm = nn.LSTM(embedding_size,hidden_size, bidirectional = True, batch_first = True)\n",
    "        self.linear = nn.Linear(2*hidden_size, num_class) # 2 because forward and backward concatenate\n",
    "\n",
    "    def forward(self, x, xlengths): \n",
    "        x = pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        x, _ = pad_packed_sequence(x, batch_first=True)\n",
    "        word_embedding = self.wordembed(x) # x is of size(batchsize, seq_len), out is of size (batchsize, seq_len, embedding_size = 100)\n",
    "        # word_embedding = self.fcembed(word_embedding)\n",
    "        word_embedding = self.dropout(word_embedding) # dropout\n",
    "\n",
    "        out, (h,c) = self.bilstm(word_embedding) #'out' has dimension(batchsize, seq_len, 2*hidden_size)\n",
    "        out = self.linear(out) # now 'out' has dimension(batchsize, seq_len, num_class)\n",
    "        out = out.view(-1, out.shape[2]) # shape (128*seqlen, 18)\n",
    "        out = F.log_softmax(out, dim=1) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
    "def load_data(datapath, buildvocab_tags= True, vocab = None, nertags = None):\n",
    "    if(buildvocab_tags == True):\n",
    "        all_words = []\n",
    "        all_tags = []\n",
    "        with open(datapath) as f:\n",
    "            lines = f.readlines()\n",
    "            sent_num = 0\n",
    "            for line in lines[2:]: #1: so that the first blank line isn't taken into account\n",
    "                if(line == \"\\n\"):\n",
    "                    sent_num+=1\n",
    "                else:\n",
    "                    line_sep = line.split(sep = \" \")\n",
    "                    all_words.append(line_sep[0])\n",
    "                    all_tags.append(line_sep[3][:-1])\n",
    "                    \n",
    "        words = list(set(all_words))\n",
    "        tags = list(set(all_tags))\n",
    "\n",
    "        vocab = {}\n",
    "        vocab['<pad>'] = 0 # for padding input sequences\n",
    "        vocab['<oov>'] = 1\n",
    "        for i, word in enumerate(words):\n",
    "            vocab[word] = i+2\n",
    "            \n",
    "        nertags = {}\n",
    "        nertags['padtag'] = 0\n",
    "        for i,nertag in enumerate(tags):\n",
    "            nertags[nertag] = i+1\n",
    "\n",
    "    train_sent = []\n",
    "    train_tags = []\n",
    "    with open(datapath) as f:\n",
    "        lines = f.readlines()\n",
    "        sent_num = 0\n",
    "        sentence = []\n",
    "        tag = []\n",
    "        for line in lines[2:]: #1: so that the first blank line isn't taken into account\n",
    "            if(line == \"\\n\"):\n",
    "                sent_num+=1\n",
    "                train_sent.append(sentence)\n",
    "                train_tags.append(tag)\n",
    "                sentence = []\n",
    "                tag = []\n",
    "            else:\n",
    "                line_sep = line.split(sep = \" \")\n",
    "                if(line_sep[0] in vocab.keys()):\n",
    "                    sentence.append(vocab[line_sep[0]])\n",
    "                else:\n",
    "                    sentence.append(vocab['<oov>'])\n",
    "                    \n",
    "                tag.append(nertags[line_sep[3][:-1]])\n",
    "\n",
    "    # padding the sentences at the end\n",
    "    seq_maxlen = max(len(x) for x in train_sent)\n",
    "    x_lengths = [len(x) for x in train_sent]\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    for sent, tags in zip(train_sent, train_tags):\n",
    "        length_toappend = seq_maxlen - len(sent)\n",
    "        Xtrain.append(sent+[0]*length_toappend)\n",
    "        Ytrain.append(tags+[0]*length_toappend)\n",
    "\n",
    "\n",
    "    Xtrain = torch.Tensor(Xtrain)\n",
    "    Ytrain = torch.Tensor(Ytrain)\n",
    "    x_lengths = torch.Tensor(x_lengths)\n",
    "    print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
    "    \n",
    "    return Xtrain, Ytrain, x_lengths, vocab, nertags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14986, 113]) torch.Size([14986, 113]) torch.Size([14986])\n",
      "torch.Size([3465, 109]) torch.Size([3465, 109]) torch.Size([3465])\n"
     ]
    }
   ],
   "source": [
    "traindatapath = 'data/train.txt'\n",
    "devdatapath = 'data/dev.txt'\n",
    "testdatapath = 'data/test.txt'\n",
    "\n",
    "\n",
    "Xtrain, Ytrain, x_trainlengths, vocab, nertags = load_data(traindatapath, buildvocab_tags=True)\n",
    "Xdev, Ydev, x_devlengths, _, _ = load_data(devdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = TensorDataset(Xtrain, Ytrain, x_trainlengths)\n",
    "Trainloader = DataLoader(traindataset, batch_size= 128, shuffle=True)\n",
    "\n",
    "devdataset = TensorDataset(Xdev, Ydev, x_devlengths)\n",
    "Devloader = DataLoader(devdataset, batch_size= 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 2., 2.,  ..., 4., 2., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trainlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MY MODEL!!! \n",
    "\n",
    "pre_embeddings = 'glove'\n",
    "Expname = 'BILSTM_glove'\n",
    "rootpath = 'out/'\n",
    "glove_embeddings_file = 'data/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD EMBEDDINGS\n",
    "embedding_size = 100\n",
    "if(pre_embeddings == \"glove\"):\n",
    "    gloveembeddings_index = {}\n",
    "    with io.open(glove_embeddings_file, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:],dtype='float32')\n",
    "            gloveembeddings_index[word] = coefs\n",
    "\n",
    "    #using vocab and Xtrain, Xvalid, get pretrained glove word embeddings\n",
    "    glove_embeds = np.zeros((len(vocab), embedding_size))\n",
    "    for word in vocab.keys():\n",
    "        if(word in gloveembeddings_index.keys()):\n",
    "            # for the pad word let theembedding be all zeros\n",
    "            glove_embeds[vocab[word]] = gloveembeddings_index[word]\n",
    "        else:\n",
    "            glove_embeds[vocab[word]] = np.random.randn(embedding_size)\n",
    "    word_embeds = torch.Tensor(glove_embeds)\n",
    "    # print(glove_embeds.shape) # shape (vocablength , embedding dim)\n",
    "\n",
    "if(pre_embeddings == \"random\"):\n",
    "    num_words = len(vocab)\n",
    "    word_embeds = torch.rand(num_words, embedding_size)\n",
    "\n",
    "# hence we get word_embeds which we could use afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes to be looked at for performance metrics\n",
    "imp_classes = [nertags[tag] for tag in nertags.keys()]\n",
    "imp_classes.remove(nertags['padtag'])\n",
    "imp_classes.remove(nertags['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = True, pretrained_embed = word_embeds).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) \n",
    "lossfunction = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM(\n",
      "  (wordembed): Embedding(23626, 100)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (bilstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=200, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y, ypred, nertags):\n",
    "    y = y.numpy()\n",
    "    ypred = ypred.numpy()\n",
    "    mask = (y != nertags['padtag']) * (y != nertags['O'])\n",
    "    y = y*mask\n",
    "    ypred = ypred*mask\n",
    "    acc = ((y==ypred)*mask).sum()/mask.sum()\n",
    "    microf1 = f1_score(y, ypred, labels = imp_classes, average='micro')\n",
    "    macrof1 = f1_score(y, ypred, labels = imp_classes, average='macro')\n",
    "\n",
    "    return acc, microf1, macrof1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "        with torch.no_grad():\n",
    "            validloss = 0\n",
    "            acc = 0\n",
    "            microf1 = 0\n",
    "            macrof1 = 0\n",
    "            i = 0\n",
    "            for step, (X, Y, xlen) in enumerate(loader):\n",
    "                Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
    "                Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
    "                ypred = model(X.long().to(device), xlen.to(device))#.permute(0, 2, 1)\n",
    "                vloss = lossfunction(ypred.to('cpu'), Y.view(-1).type(torch.LongTensor))\n",
    "                validloss+=vloss.item()\n",
    "                acc_, microf1_, macrof1_ = performance(Y.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
    "                acc+=acc_\n",
    "                microf1 += microf1_\n",
    "                macrof1 += macrof1_\n",
    "                i+=1\n",
    "\n",
    "        return validloss/i, acc/i, microf1/i, macrof1/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlosslist = []\n",
    "trainacclist = [] #accuracy except pad, O\n",
    "trainmicrof1list = []\n",
    "trainmacrof1list = []\n",
    "\n",
    "validlosslist = []\n",
    "valacclist = []\n",
    "valmicrof1list = []\n",
    "valmacrof1list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.0043844130669047415, microF1 = 0.007660170284938238, macroF1 = 0.005465759757512896\n",
      "training accuracy = 0.021424579351787893, microF1 = 0.03631135520314613, macroF1 = 0.020619012429528037\n",
      "training accuracy = 0.054490372387793036, microF1 = 0.0832964324464358, macroF1 = 0.04711821458953126\n",
      "training accuracy = 0.10471694354442534, microF1 = 0.14386338696334597, macroF1 = 0.08828613726428802\n",
      "training accuracy = 0.15968397197629958, microF1 = 0.20377400363797873, macroF1 = 0.1367340886001963\n",
      "\n",
      "epoch = 0, training_loss = 0.17300437251895162, validation_loss =0.08897496560322386, training_acc = 0.20143161519030622, validation_acc =0.4490270422811661\n",
      "training accuracy = 0.5297113076852847, microF1 = 0.5800255513469111, macroF1 = 0.5160532834665492\n",
      "training accuracy = 0.5582929090738242, microF1 = 0.6063941156259935, macroF1 = 0.5468235139129346\n",
      "training accuracy = 0.5849203182444765, microF1 = 0.6312545451862273, macroF1 = 0.5697975647536416\n",
      "training accuracy = 0.6036727038746763, microF1 = 0.6489586063353918, macroF1 = 0.591130175782532\n",
      "training accuracy = 0.620887852732579, microF1 = 0.66522323145881, macroF1 = 0.6102987521357554\n",
      "\n",
      "epoch = 1, training_loss = 0.06194662155930774, validation_loss =0.06240237597376108, training_acc = 0.634725540274586, validation_acc =0.6675194520692502\n",
      "training accuracy = 0.7715420875454048, microF1 = 0.8034923558755942, macroF1 = 0.7673477506532006\n",
      "training accuracy = 0.7681077763205528, microF1 = 0.7991145975976242, macroF1 = 0.761317972537215\n",
      "training accuracy = 0.7736903016193662, microF1 = 0.8044812281441551, macroF1 = 0.7694248304871469\n",
      "training accuracy = 0.7821532004968486, microF1 = 0.8122182906920069, macroF1 = 0.775633245690918\n",
      "training accuracy = 0.7863267467604154, microF1 = 0.8158846950705114, macroF1 = 0.7788955075582297\n",
      "\n",
      "epoch = 2, training_loss = 0.037056400046005085, validation_loss =0.052573330367782285, training_acc = 0.790434283124422, validation_acc =0.7395452369049328\n",
      "training accuracy = 0.8544123836146541, microF1 = 0.8744262719895569, macroF1 = 0.8507551098616791\n",
      "training accuracy = 0.8555718950690265, microF1 = 0.8761480975927927, macroF1 = 0.845925346786236\n",
      "training accuracy = 0.8603093634030525, microF1 = 0.8806418399421667, macroF1 = 0.8535055357735848\n",
      "training accuracy = 0.8618649099085416, microF1 = 0.8826579336171397, macroF1 = 0.856188966008514\n",
      "training accuracy = 0.8625587920957032, microF1 = 0.8829749070500597, macroF1 = 0.8548673055274464\n",
      "\n",
      "epoch = 3, training_loss = 0.024834947084408192, validation_loss =0.04591018912781562, training_acc = 0.8632181641549878, validation_acc =0.7699627781288377\n",
      "training accuracy = 0.892296304194506, microF1 = 0.9065694238011074, macroF1 = 0.8831765101275307\n",
      "training accuracy = 0.8961835784936683, microF1 = 0.9107845504946143, macroF1 = 0.8861359369826212\n",
      "training accuracy = 0.8990680967158702, microF1 = 0.9135453958405321, macroF1 = 0.8906669853402385\n",
      "training accuracy = 0.8989917895463444, microF1 = 0.9134493695208262, macroF1 = 0.8914446060187091\n",
      "training accuracy = 0.9002131450862698, microF1 = 0.9146401157255093, macroF1 = 0.8937960228127121\n",
      "\n",
      "epoch = 4, training_loss = 0.018103624591446023, validation_loss =0.045966560553227155, training_acc = 0.8999584234579642, validation_acc =0.7929601848194229\n",
      "training accuracy = 0.922444033359442, microF1 = 0.9341368832436701, macroF1 = 0.9135616497471395\n",
      "training accuracy = 0.9231437891034028, microF1 = 0.934562573820679, macroF1 = 0.9164106467841039\n",
      "training accuracy = 0.9244027824653944, microF1 = 0.9356214451912293, macroF1 = 0.9175866139414164\n",
      "training accuracy = 0.9248823455738966, microF1 = 0.9365943516848394, macroF1 = 0.9170473824118924\n",
      "training accuracy = 0.9243155481874029, microF1 = 0.9363868205303024, macroF1 = 0.9169518445202438\n",
      "\n",
      "epoch = 5, training_loss = 0.013666877651318781, validation_loss =0.046277346122743826, training_acc = 0.9251544544554625, validation_acc =0.785821087913373\n",
      "training accuracy = 0.930098772383436, microF1 = 0.9402232507640261, macroF1 = 0.9289203713615917\n",
      "training accuracy = 0.9284843538107218, microF1 = 0.939698286676902, macroF1 = 0.9261074255589153\n",
      "training accuracy = 0.9279048049319178, microF1 = 0.9396053868758392, macroF1 = 0.9273232771368495\n",
      "training accuracy = 0.9301340510695748, microF1 = 0.9413520845757706, macroF1 = 0.9280329246075182\n",
      "training accuracy = 0.9280230922430429, microF1 = 0.9397628119286096, macroF1 = 0.924050664923558\n",
      "\n",
      "epoch = 6, training_loss = 0.013304566917151718, validation_loss =0.04886673477345279, training_acc = 0.9271351596743208, validation_acc =0.7812463073136314\n",
      "training accuracy = 0.9299456143536866, microF1 = 0.9397991868841586, macroF1 = 0.9274063266331318\n",
      "training accuracy = 0.9308895463288561, microF1 = 0.9413201352241782, macroF1 = 0.9289398982295111\n",
      "training accuracy = 0.9301853507882031, microF1 = 0.9411037346558155, macroF1 = 0.9273602789230558\n",
      "training accuracy = 0.9292327791473989, microF1 = 0.9405887799832509, macroF1 = 0.9270151704108814\n",
      "training accuracy = 0.9278191295380642, microF1 = 0.93898025112957, macroF1 = 0.9235193491266394\n",
      "\n",
      "epoch = 7, training_loss = 0.01311206133736266, validation_loss =0.047852094152144024, training_acc = 0.9290850219372351, validation_acc =0.791052923037662\n",
      "training accuracy = 0.9358802477744345, microF1 = 0.9453561561462245, macroF1 = 0.9299721551795278\n",
      "training accuracy = 0.9278989523503154, microF1 = 0.9390945604982922, macroF1 = 0.9215189665350141\n",
      "training accuracy = 0.9304491291863519, microF1 = 0.9411018953662099, macroF1 = 0.9252324231896182\n",
      "training accuracy = 0.9284655741362856, microF1 = 0.9395217970938282, macroF1 = 0.9236715860154849\n",
      "training accuracy = 0.9288250640755176, microF1 = 0.9397359891934707, macroF1 = 0.9243220008894679\n",
      "\n",
      "epoch = 8, training_loss = 0.01275284500729482, validation_loss =0.04866837078173246, training_acc = 0.9290184273479658, validation_acc =0.7837687411022038\n",
      "training accuracy = 0.9412585174176156, microF1 = 0.9498232181617675, macroF1 = 0.9358550419066631\n",
      "training accuracy = 0.9350631925780473, microF1 = 0.9457363236747667, macroF1 = 0.9299022939567091\n",
      "training accuracy = 0.9327653014371301, microF1 = 0.9437288843020812, macroF1 = 0.9297399751803439\n",
      "training accuracy = 0.9338968231507795, microF1 = 0.9441304538307063, macroF1 = 0.9304061056019655\n",
      "training accuracy = 0.9318910968153045, microF1 = 0.9424892927003751, macroF1 = 0.9280524685854552\n",
      "\n",
      "epoch = 9, training_loss = 0.013029429905700609, validation_loss =0.049887114470558505, training_acc = 0.9308569325756056, validation_acc =0.775252006111691\n"
     ]
    }
   ],
   "source": [
    "# Model is ready now we have to train using cross entropy loss\n",
    "num_epochs = 10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# validloss = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    if(epoch == 5):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "        \n",
    "    totalloss, acc, microf1, macrof1 = 0, 0, 0, 0\n",
    "    for step, (Xbatch ,Ybatch, xbatch_len) in enumerate(Trainloader):\n",
    "        #make gradients 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        Ybatch = pack_padded_sequence(Ybatch, xbatch_len, batch_first=True, enforce_sorted=False)\n",
    "        Ybatch, y_lengths = pad_packed_sequence(Ybatch, batch_first=True)\n",
    "\n",
    "        #get output from model and claculate loss\n",
    "        ypred = model(Xbatch.long().to(device), xbatch_len.to(device))#.permute(0, 2, 1)\n",
    "        \n",
    "        acc_, microf1_, macrof1_ = performance(Ybatch.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
    "        acc+= acc_\n",
    "        microf1+=microf1_\n",
    "        macrof1+=macrof1_\n",
    "        if(step%20 == 0 and step !=0):\n",
    "            print(\"training accuracy = {}, microF1 = {}, macroF1 = {}\".format(acc/(step+1), microf1/(step+1), macrof1/(step+1)))\n",
    "            \n",
    "        loss = lossfunction(ypred.to('cpu'), Ybatch.view(-1).type(torch.LongTensor)) #Ybatch has dimension (batchsize, seqlen), ypred has dimension(batchsize, num_classes, seqlen)\n",
    "        totalloss += loss.item()\n",
    "\n",
    "        #backward and step\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
    "        optimizer.step()\n",
    "        \n",
    "    trainlosslist.append(totalloss/(step+1))\n",
    "    trainacclist.append(acc/(step+1))\n",
    "    trainmicrof1list.append(microf1/(step+1))\n",
    "    trainmacrof1list.append(macrof1/(step+1))\n",
    "\n",
    "    # model validation loss and scheduler step for learning rate change if required\n",
    "    val_loss, val_acc, val_microf1, val_macrof1  = validate(model, Devloader)\n",
    "    validlosslist.append(val_loss)\n",
    "    valacclist.append(val_acc)\n",
    "    valmicrof1list.append(val_microf1)\n",
    "    valmacrof1list.append(val_macrof1)\n",
    "        \n",
    "    # scheduler.step(val_loss)\n",
    "    print('\\nepoch = {}, training_loss = {}, validation_loss ={}, training_acc = {}, validation_acc ={}'.format(epoch, trainlosslist[-1], validlosslist[-1], trainacclist[-1], valacclist[-1]))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'out/word_bilstm.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (wordembed): Embedding(23626, 100)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bilstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=200, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(rootpath):\n",
    "       os.mkdir(rootpath)\n",
    "\n",
    "if not os.path.exists(rootpath+Expname):\n",
    "    os.mkdir(rootpath+Expname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make id2tag\n",
    "id2tag = {}\n",
    "for tag in nertags.keys():\n",
    "    if(tag == 'padtag'):\n",
    "         id2tag[nertags[tag]] = 'O' # because we dont want the model to predict 'padtag' tags\n",
    "    else:\n",
    "        id2tag[nertags[tag]] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_metrics(model,loader):\n",
    "    y_predicted = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for step, (X, Y, xlen) in enumerate(loader):\n",
    "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
    "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
    "            ypred = model(X.long().to(device), xlen.to(device))#.permute(0, 2, 1)\n",
    "            ypred = torch.argmax(ypred.to('cpu'), dim = 1)\n",
    "            ypred = ypred.view(Y.shape[0], -1)\n",
    "            y_predicted.append(ypred)\n",
    "            y_true.append(Y)\n",
    "\n",
    "    y_predicted_list = []\n",
    "    y_true_list = []\n",
    "    for i in range(len(y_predicted)):\n",
    "        for j in range(y_predicted[i].shape[0]):\n",
    "            sent_pred = []\n",
    "            sent_true = []\n",
    "            for x in range(y_predicted[i].shape[1]):\n",
    "                sent_pred.append(id2tag[int(y_predicted[i][j, x])])\n",
    "                sent_true.append(id2tag[int(y_true[i][j, x])])\n",
    "            y_predicted_list.append(sent_pred)\n",
    "            y_true_list.append(sent_true)\n",
    "    \n",
    "    return seq_f1_score(y_true_list, y_predicted_list), seq_accuracy_score(y_true_list, y_predicted_list), seq_classification_report(y_true_list, y_predicted_list, digits = 3)\n",
    "\n",
    "    #return y_predicted, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3683, 124]) torch.Size([3683, 124]) torch.Size([3683])\n",
      "PERFORMANCE ON Test DATA\n",
      "MicroF1 = 0.6999191156645996\n",
      "Accuracy = 0.9365263045108754\n",
      "------------Classification Report-------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC      0.841     0.712     0.771      1668\n",
      "        MISC      0.588     0.655     0.620       702\n",
      "         ORG      0.746     0.604     0.668      1661\n",
      "         PER      0.640     0.769     0.699      1617\n",
      "\n",
      "   micro avg      0.711     0.689     0.700      5648\n",
      "   macro avg      0.704     0.685     0.689      5648\n",
      "weighted avg      0.724     0.689     0.701      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test DATASET\n",
    "Xtest, Ytest, x_testlengths, _, _ = load_data(testdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
    "\n",
    "testdataset = TensorDataset(Xtest, Ytest, x_testlengths)\n",
    "loader_test = DataLoader(testdataset, batch_size= 1, shuffle=False)\n",
    "test_f1_conll, test_acc_conll, test_classif_report = final_metrics(model, loader_test)\n",
    "\n",
    "print(\"PERFORMANCE ON Test DATA\")\n",
    "print('MicroF1 = {}'.format(test_f1_conll))\n",
    "print('Accuracy = {}'.format(test_acc_conll))\n",
    "print('------------Classification Report-------------')\n",
    "print(test_classif_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_predictions(model, loader, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        with torch.no_grad():\n",
    "            for step, (X, Y, xlen) in enumerate(loader):\n",
    "                Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
    "                Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
    "                ypred = model(X.long().to(device), xlen.to(device))\n",
    "                ypred = torch.argmax(ypred.to('cpu'), dim=1)\n",
    "                ypred = ypred.view(Y.shape[0], -1)\n",
    "                for i in range(len(ypred)):\n",
    "                    for j in range(len(ypred[i])):\n",
    "                        word = id2word[int(X[i, j])]\n",
    "                        tag = id2tag[int(ypred[i, j])]\n",
    "                        f.write(f\"{word}\\t{tag}\\n\")\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is a tensor containing word IDs\n",
    "id2word = {id: word for word, id in vocab.items()}  # Assuming vocab is a dictionary mapping words to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_predictions(model, loader_test, 'out/predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input and output files\n",
    "with open('data/test.txt', 'r') as f_input, open('data/gold.txt', 'w') as f_output:\n",
    "    # Read each line from the input file\n",
    "    for line_number, line in enumerate(f_input):\n",
    "        if line_number < 2:\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            f_output.write('\\n')\n",
    "            continue  \n",
    "        columns = line.split()\n",
    "        if len(columns) < 2:\n",
    "            continue  \n",
    "        word = columns[0]\n",
    "        ner_tag = columns[-1]\n",
    "        f_output.write(word + '\\t' + ner_tag + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBIO(path):\n",
    "    ents = []\n",
    "    curEnts = []\n",
    "    for line in open(path):\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            ents.append(curEnts)\n",
    "            curEnts = []\n",
    "        elif line[0] == '#' and len(line.split('\\t')) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            curEnts.append(line.split('\\t')[1])\n",
    "    return ents\n",
    "\n",
    "def toSpans(tags):\n",
    "    spans = set()\n",
    "    for beg in range(len(tags)):\n",
    "        if tags[beg][0] == 'B':\n",
    "            end = beg\n",
    "            for end in range(beg+1, len(tags)):\n",
    "                if tags[end][0] != 'I':\n",
    "                    break\n",
    "            spans.add(str(beg) + '-' + str(end) + ':' + tags[beg][2:])\n",
    "            #print(end-beg)\n",
    "    return spans\n",
    "\n",
    "def getInstanceScores(predPath, goldPath):\n",
    "    goldEnts = readBIO(goldPath)\n",
    "    predEnts = readBIO(predPath)\n",
    "    entScores = []\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for goldEnt, predEnt in zip(goldEnts, predEnts):\n",
    "        goldSpans = toSpans(goldEnt)\n",
    "        predSpans = toSpans(predEnt)\n",
    "        overlap = len(goldSpans.intersection(predSpans))\n",
    "        tp += overlap\n",
    "        fp += len(predSpans) - overlap\n",
    "        fn += len(goldSpans) - overlap\n",
    "        \n",
    "    prec = 0.0 if tp+fp == 0 else tp/(tp+fp)\n",
    "    rec = 0.0 if tp+fn == 0 else tp/(tp+fn)\n",
    "    f1 = 0.0 if prec+rec == 0.0 else 2 * (prec * rec) / (prec + rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 'out/predictions.txt'\n",
    "gold = 'data/gold.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span-F1 score - word-biLSTM  0.7361733931240658\n"
     ]
    }
   ],
   "source": [
    "score = getInstanceScores(pred,gold)\n",
    "print('Span-F1 score - word-biLSTM ', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
