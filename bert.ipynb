{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_metric, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, DataCollatorForTokenClassification, Trainer\n",
    "import evaluate\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "from huggingface_hub import notebook_login, Repository, get_full_repo_name\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_og(file_path):\n",
    "    # Initialize lists to store data\n",
    "    sentence_ids = []\n",
    "    tokens = []\n",
    "    # pos_tags = []\n",
    "    # chunk_tags = []\n",
    "    ner_tags = []\n",
    "\n",
    "    # Initialize list to store sentences\n",
    "    sentences = []\n",
    "\n",
    "    # Open the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Initialize sentence ID counter\n",
    "        sentence_id = 0\n",
    "\n",
    "        # Initialize lists to store sentence-level data\n",
    "        sentence_tokens = []\n",
    "        # sentence_pos_tags = []\n",
    "        # sentence_chunk_tags = []\n",
    "        sentence_ner_tags = []\n",
    "\n",
    "        # Iterate through lines\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                if sentence_tokens:  # If the sentence has tokens\n",
    "                    # Append sentence data to lists\n",
    "                    sentence_ids.append(sentence_id)\n",
    "                    tokens.append(sentence_tokens)\n",
    "                    # pos_tags.append(sentence_pos_tags)\n",
    "                    # chunk_tags.append(sentence_chunk_tags)\n",
    "                    ner_tags.append(sentence_ner_tags)\n",
    "                    sentences.append(sentence_tokens)  # Add to sentences list\n",
    "\n",
    "                    # Reset for the next sentence\n",
    "                    sentence_tokens = []\n",
    "                    # sentence_pos_tags = []\n",
    "                    # sentence_chunk_tags = []\n",
    "                    sentence_ner_tags = []\n",
    "                sentence_id += 1  # Increment sentence ID\n",
    "                continue\n",
    "\n",
    "            # # Skip the initial -DOCSTART- line\n",
    "            # if line.startswith('-DOCSTART-'):\n",
    "            #     continue\n",
    "\n",
    "            # Split line by whitespace\n",
    "            parts = line.split()\n",
    "\n",
    "            # Extract data\n",
    "            token = parts[0]\n",
    "            ner_tag = parts[3]\n",
    "\n",
    "            # Append data to sentence-level lists\n",
    "            sentence_tokens.append(token)\n",
    "            # sentence_pos_tags.append(0)  # Append 0 for pos_tags\n",
    "            # sentence_chunk_tags.append(0)  # Append 0 for chunk_tags\n",
    "            sentence_ner_tags.append(ner_tag)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'sentence_id': sentence_ids,\n",
    "        'tokens': tokens,\n",
    "        # 'pos_tags': pos_tags,\n",
    "        # 'chunk_tags': chunk_tags,\n",
    "        'ner_tags': ner_tags\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not necessary for now\n",
    "\n",
    "# Define dataset paths\n",
    "traindatapath = \"data/train.txt\"\n",
    "devdatapath = \"data/dev.txt\"\n",
    "testdatapath = \"data/test.txt\"\n",
    "\n",
    "train_df, train_sentences = read_data_og(traindatapath)\n",
    "val_df, val_sentences = read_data_og(devdatapath)\n",
    "test_df, test_sentences = read_data_og(testdatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique ner tags\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "label2id_int = {'O': 0,\n",
    " 'B-PER': 1,\n",
    " 'I-PER': 2,\n",
    " 'B-ORG': 3,\n",
    " 'I-ORG': 4,\n",
    " 'B-LOC': 5,\n",
    " 'I-LOC': 6,\n",
    " 'B-MISC': 7,\n",
    " 'I-MISC': 8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    previous_word_idx = None\n",
    "\n",
    "    for word_id in word_ids:\n",
    "        \n",
    "        if word_id == None:\n",
    "            current_word = word_id\n",
    "            new_labels.append(-100) # -100 is ignored\n",
    "        \n",
    "        elif word_id != previous_word_idx:\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "\n",
    "        else:\n",
    "            new_labels.append(-100)\n",
    "        previous_word_idx = word_id\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(data):\n",
    "    tokenized_inputs = tokenizer(data['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    all_labels = data['ner_tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ner_tags_to_ids(data):\n",
    "    data['ner_tags'] = [[label2id_int[tag] for tag in tags] for tags in data['ner_tags']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02038c0af3a346839d55526119a0fca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13636ab5b1247c8b27f61fc57491cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d450e78e98624167a4ce7243230f6c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115157477a9b42528f98ca04072fa1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, train_sentences = read_data_og(traindatapath)\n",
    "val_df, val_sentences = read_data_og(devdatapath)\n",
    "test_df, test_sentences = read_data_og(testdatapath)\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "train_dataset = train_dataset.map(map_ner_tags_to_ids, batched=True)\n",
    "test_dataset = test_dataset.map(map_ner_tags_to_ids, batched=True)\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(tokenized_datasets[\"train\"], shuffle = True, batch_size=8, collate_fn=data_collator)\n",
    "# val_loader = DataLoader(tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator)\n",
    "# test_loader = DataLoader(tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {label: i for i, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_name,id2label = id2label, label2id=label2id, num_labels=len(label2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels to a list of lists if it's a set\n",
    "    if isinstance(labels, set):\n",
    "        labels = [labels]\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x00000200390B9540>\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 2e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerator & LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerator = Accelerator()\n",
    "\n",
    "# model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "#     model, optimizer, train_loader, val_loader\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_train_epochs = 5\n",
    "# num_update_steps_per_epoch = len(train_loader)\n",
    "# num_training_steps = num_train_epochs * len(train_loader)\n",
    "\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     \"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=num_training_steps\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c4c632de4e41fe8f7b02fcdda43a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raiviswastaken/bert-finetuned-ner-Raivis'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_saved = \"bert-finetuned-ner-Raivis\"\n",
    "# repo_name = get_full_repo_name(model_saved)\n",
    "# repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"HF_HOME\"] = \"true\"\n",
    "# output_dir = \"bert-finetuned-ner-Raivis\"\n",
    "# # repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raivi\\AppData\\Local\\Temp\\ipykernel_79376\\3730763129.py:14: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b85d928e21848bf9f687e13f017fd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1587, 'learning_rate': 1.7865528281750267e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd76a63038d1456f86c61563e995615a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09059310704469681, 'eval_precision': 0.8983021179765447, 'eval_recall': 0.9086402266288952, 'eval_f1': 0.9034415984508405, 'eval_accuracy': 0.9817425963228046, 'eval_runtime': 19.0902, 'eval_samples_per_second': 192.978, 'eval_steps_per_second': 12.1, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0477, 'learning_rate': 1.5731056563500536e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0272, 'learning_rate': 1.3596584845250803e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb983f2218147a8a64cde3e09a0e68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10664570331573486, 'eval_precision': 0.8982285515804098, 'eval_recall': 0.9157223796033994, 'eval_f1': 0.9068911099421356, 'eval_accuracy': 0.981978313975914, 'eval_runtime': 28.6825, 'eval_samples_per_second': 128.441, 'eval_steps_per_second': 8.054, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.022, 'learning_rate': 1.146211312700107e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0139, 'learning_rate': 9.327641408751335e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f370d836f948e1a7684575105f64c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12913185358047485, 'eval_precision': 0.8957936645317639, 'eval_recall': 0.9162535410764873, 'eval_f1': 0.9059080962800876, 'eval_accuracy': 0.9813783054043629, 'eval_runtime': 31.2197, 'eval_samples_per_second': 118.002, 'eval_steps_per_second': 7.399, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-3000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0117, 'learning_rate': 7.193169690501601e-06, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-3500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0078, 'learning_rate': 5.058697972251868e-06, 'epoch': 3.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a46e250516405b96a63bc1d629007f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12599104642868042, 'eval_precision': 0.9030398322851153, 'eval_recall': 0.9151912181303116, 'eval_f1': 0.9090749208582483, 'eval_accuracy': 0.982256889384134, 'eval_runtime': 30.1141, 'eval_samples_per_second': 122.335, 'eval_steps_per_second': 7.671, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-4000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0069, 'learning_rate': 2.924226254002135e-06, 'epoch': 4.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory bert-finetuned-ner-Raivis\\checkpoint-4500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0045, 'learning_rate': 7.897545357524014e-07, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45848bf508214cd9bf3455a8fa7bf117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13532161712646484, 'eval_precision': 0.9015966678236723, 'eval_recall': 0.9197946175637394, 'eval_f1': 0.9106047326906223, 'eval_accuracy': 0.9824068915270218, 'eval_runtime': 27.3286, 'eval_samples_per_second': 134.804, 'eval_steps_per_second': 8.453, 'epoch': 5.0}\n",
      "{'train_runtime': 1956.1325, 'train_samples_per_second': 38.308, 'train_steps_per_second': 2.395, 'train_loss': 0.032211088943379665, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4685, training_loss=0.032211088943379665, metrics={'train_runtime': 1956.1325, 'train_samples_per_second': 38.308, 'train_steps_per_second': 2.395, 'train_loss': 0.032211088943379665, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saved = \"bert-finetuned-ner-Raivis\"\n",
    "args = TrainingArguments(\n",
    "    model_saved,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = compute_metrics,\n",
    "    optimizers = (optimizer, None)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"models/bert-ner-Raivis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f21cb8ac444befbc822dd0eef2b60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.9306634787806336,\n",
       "  'recall': 0.9334532374100719,\n",
       "  'f1': 0.9320562705776714,\n",
       "  'number': 1668},\n",
       " 'MISC': {'precision': 0.7776280323450134,\n",
       "  'recall': 0.8219373219373219,\n",
       "  'f1': 0.799168975069252,\n",
       "  'number': 702},\n",
       " 'ORG': {'precision': 0.8704663212435233,\n",
       "  'recall': 0.9102950030102348,\n",
       "  'f1': 0.8899352560329605,\n",
       "  'number': 1661},\n",
       " 'PER': {'precision': 0.962111801242236,\n",
       "  'recall': 0.9579468150896723,\n",
       "  'f1': 0.9600247908273939,\n",
       "  'number': 1617},\n",
       " 'overall_precision': 0.9015966678236723,\n",
       " 'overall_recall': 0.9197946175637394,\n",
       " 'overall_f1': 0.9106047326906223,\n",
       " 'overall_accuracy': 0.9824068915270218}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(tokenized_test_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_predictions = [\n",
    "    [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_output(sentences, predictions):\n",
    "    formatted_data = []\n",
    "    for sentence, prediction in zip(sentences, predictions):\n",
    "        for word, tag in zip(sentence, prediction):\n",
    "            formatted_data.append([word, tag])\n",
    "        # Add an empty line after each sentence\n",
    "        formatted_data.append([\"\", \"\"])\n",
    "    return formatted_data\n",
    "\n",
    "formatted_output = convert_to_output(test_sentences, true_predictions)\n",
    "\n",
    "# Save formatted data to output file in format word tag, sentences are separated by empty line\n",
    "def save_to_output_file(formatted_data, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for data in formatted_data:\n",
    "            file.write(data[0] + '\\t' + data[1] + '\\n')\n",
    "        file.write('\\n')  # Add an empty line after each sentence\n",
    "\n",
    "outputname = \"bert_gold_22052024.txt\"\n",
    "save_to_output_file(formatted_output, outputname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143058243885273\n"
     ]
    }
   ],
   "source": [
    "bert_InstanceScores = getInstanceScores(\"bert_gold_22052024.txt\", \"data/gold.txt\")\n",
    "print(bert_InstanceScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_rates = {\n",
    "    'capitalization_swap': [0.1, 0.15, 0.2, 0.25, 0.3], \n",
    "    'character_swap': [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'character_removal': [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'character_replacement': [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_grouped(file_path):\n",
    "    # Initialize lists to store data\n",
    "    sentence_ids = []\n",
    "    tokens = []\n",
    "    pos_tags = []\n",
    "    chunk_tags = []\n",
    "    ner_tags = []\n",
    "\n",
    "    # Initialize list to store sentences\n",
    "    sentences = []\n",
    "\n",
    "    # Open the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Initialize sentence ID counter\n",
    "        sentence_id = 0\n",
    "\n",
    "        # Initialize lists to store sentence-level data\n",
    "        sentence_tokens = []\n",
    "        sentence_pos_tags = []\n",
    "        sentence_chunk_tags = []\n",
    "        sentence_ner_tags = []\n",
    "\n",
    "        # Iterate through lines\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Skip empty lines\n",
    "            if not line:\n",
    "                if sentence_tokens:  # If the sentence has tokens\n",
    "                    # Append sentence data to lists\n",
    "                    sentence_ids.append(sentence_id)\n",
    "                    tokens.append(sentence_tokens)\n",
    "                    pos_tags.append(sentence_pos_tags)\n",
    "                    chunk_tags.append(sentence_chunk_tags)\n",
    "                    ner_tags.append(sentence_ner_tags)\n",
    "                    sentences.append(sentence_tokens)  # Add to sentences list\n",
    "\n",
    "                    # Reset for the next sentence\n",
    "                    sentence_tokens = []\n",
    "                    sentence_pos_tags = []\n",
    "                    sentence_chunk_tags = []\n",
    "                    sentence_ner_tags = []\n",
    "                sentence_id += 1  # Increment sentence ID\n",
    "                continue\n",
    "\n",
    "            # # Skip the initial -DOCSTART- line\n",
    "            # if line.startswith('-DOCSTART-'):\n",
    "            #     continue\n",
    "\n",
    "            # Split line by whitespace\n",
    "            parts = line.split()\n",
    "\n",
    "            # Extract data\n",
    "            token = parts[0]\n",
    "            ner_tag = parts[1]\n",
    "\n",
    "            # Append data to sentence-level lists\n",
    "            sentence_tokens.append(token)\n",
    "            sentence_pos_tags.append(0)  # Append 0 for pos_tags\n",
    "            sentence_chunk_tags.append(0)  # Append 0 for chunk_tags\n",
    "            sentence_ner_tags.append(ner_tag)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'sentence_id': sentence_ids,\n",
    "        'tokens': tokens,\n",
    "        'pos_tags': pos_tags,\n",
    "        'chunk_tags': chunk_tags,\n",
    "        'ner_tags': ner_tags\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_type in noise_rates.keys():\n",
    "    for rate in noise_rates[noise_type]:\n",
    "\n",
    "        path = f'data/altered/{noise_type}_rate_{rate}.txt'\n",
    "        outpath = f'predictions/altered/bert/{noise_type}_rate_{rate}.txt'\n",
    "\n",
    "        test_df , sentences = read_data_grouped(path)\n",
    "        test_dataset = Dataset.from_pandas(test_df)\n",
    "        test_dataset = test_dataset.map(map_ner_tags_to_ids, batched=True)\n",
    "        tokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "        predictions, labels, metrics = trainer.predict(tokenized_test_dataset)\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        true_predictions = [\n",
    "            [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        output = convert_to_output(sentences, true_predictions)\n",
    "        save_to_output_file(output,outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rob\n",
    "\n",
    "def readBIO(path):\n",
    "    ents = []\n",
    "    curEnts = []\n",
    "    for line in open(path):\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            ents.append(curEnts)\n",
    "            curEnts = []\n",
    "        elif line[0] == '#' and len(line.split('\\t')) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            curEnts.append(line.split('\\t')[1])\n",
    "    return ents\n",
    "\n",
    "def toSpans(tags):\n",
    "    spans = set()\n",
    "    for beg in range(len(tags)):\n",
    "        if tags[beg][0] == 'B':\n",
    "            end = beg\n",
    "            for end in range(beg+1, len(tags)):\n",
    "                if tags[end][0] != 'I':\n",
    "                    break\n",
    "            spans.add(str(beg) + '-' + str(end) + ':' + tags[beg][2:])\n",
    "            #print(end-beg)\n",
    "    return spans\n",
    "\n",
    "def getInstanceScores(predPath, goldPath):\n",
    "    goldEnts = readBIO(goldPath)\n",
    "    predEnts = readBIO(predPath)\n",
    "    entScores = []\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for goldEnt, predEnt in zip(goldEnts, predEnts):\n",
    "        goldSpans = toSpans(goldEnt)\n",
    "        predSpans = toSpans(predEnt)\n",
    "        overlap = len(goldSpans.intersection(predSpans))\n",
    "        tp += overlap\n",
    "        fp += len(predSpans) - overlap\n",
    "        fn += len(goldSpans) - overlap\n",
    "        \n",
    "    prec = 0.0 if tp+fp == 0 else tp/(tp+fp)\n",
    "    rec = 0.0 if tp+fn == 0 else tp/(tp+fn)\n",
    "    f1 = 0.0 if prec+rec == 0.0 else 2 * (prec * rec) / (prec + rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Type  Rate  F1 Score\n",
      "0     capitalization_swap  0.10  0.836195\n",
      "1     capitalization_swap  0.15  0.802807\n",
      "2     capitalization_swap  0.20  0.773558\n",
      "3     capitalization_swap  0.25  0.733510\n",
      "4     capitalization_swap  0.30  0.706244\n",
      "5          character_swap  0.10  0.900361\n",
      "6          character_swap  0.15  0.788925\n",
      "7          character_swap  0.20  0.638737\n",
      "8          character_swap  0.25  0.569830\n",
      "9          character_swap  0.30  0.546829\n",
      "10      character_removal  0.10  0.901050\n",
      "11      character_removal  0.15  0.781415\n",
      "12      character_removal  0.20  0.622951\n",
      "13      character_removal  0.25  0.549648\n",
      "14      character_removal  0.30  0.515959\n",
      "15  character_replacement  0.10  0.901374\n",
      "16  character_replacement  0.15  0.792342\n",
      "17  character_replacement  0.20  0.635154\n",
      "18  character_replacement  0.25  0.579648\n",
      "19  character_replacement  0.30  0.558111\n"
     ]
    }
   ],
   "source": [
    "types = []\n",
    "rates = []\n",
    "f1_score = []\n",
    "\n",
    "for noise_type in noise_rates.keys():\n",
    "    for rate in noise_rates[noise_type]:\n",
    "\n",
    "        score = getInstanceScores(f\"predictions/altered/bert/{noise_type}_rate_{rate}.txt\", \"data/gold.txt\")\n",
    "        \n",
    "        # Append data to lists\n",
    "        types.append(noise_type)\n",
    "        rates.append(rate)\n",
    "        f1_score.append(score)\n",
    "\n",
    "results = {'Type': types, 'Rate': rates, 'F1 Score': f1_score}\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('out/df_altered_bert.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
