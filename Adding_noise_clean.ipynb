{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dda6788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:37:52.333121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/florentinafabregas/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nlpaug.augmenter.word as naw\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b4c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some cleaning of lines, removing empty lines.\n",
    "def read_file_content(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        cleansed_lines = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            cleansed_lines.append(line)\n",
    "        return cleansed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32eb2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries for char replacement\n",
    "approx_dict_lower =  {\n",
    " \n",
    " 'q': ['w', 'a', 's'],\n",
    " 'w': ['q', 'e', 'a', 's', 'd'],\n",
    " 'e': ['w', 'r', 's', 'd', 'f'],\n",
    " 'r': ['e', 't', 'd', 'f', 'g'],\n",
    " 't': ['r', 'y', 'f', 'g', 'h'],\n",
    " 'y': ['t', 'u', 'g', 'h', 'j'],\n",
    " 'u': ['y', 'i', 'h', 'j', 'k'],    \n",
    " 'i': ['u', 'o', 'j', 'k', 'l'],\n",
    " 'o': ['i', 'p', 'k', 'l'],\n",
    " 'p': ['o', 'l'],\n",
    " 'a': ['q', 'w', 's', 'x', 'z'],\n",
    " 's': ['e', 'w', 'a', 'd', 'z', 'x'],\n",
    " 'd': ['r', 'e', 's', 'f', 'x', 'c'],\n",
    " 'f': ['t', 'r', 'd', 'g', 'c', 'v'],\n",
    " 'g': ['y', 't', 'f', 'h', 'v', 'b'],\n",
    " 'h': ['u', 'y', 'g', 'j', 'b', 'n'],\n",
    " 'j': ['i', 'u', 'h', 'k', 'n', 'm'],\n",
    " 'k': ['o', 'i', 'j', 'l', 'm', ','],\n",
    " 'l': ['i', 'p', 'o', 'k', ',', '.'],\n",
    " 'z': ['x', 'a', 's'],\n",
    " 'x': ['s', 'd', 'z', 'c'],\n",
    " 'c': ['d', 'f', 'x', 'v'],\n",
    " 'v': ['f', 'g', 'c', 'b'],\n",
    " 'b': ['g', 'h', 'v', 'n'],\n",
    " 'n': ['h', 'j', 'b', 'm'],\n",
    " 'm': ['j', 'k', 'n', ','],\n",
    " ',': ['k', 'l', 'm', '.'],\n",
    " '.': ['l', ',']\n",
    "    }\n",
    "\n",
    "approx_dict_upper = {\n",
    "    'Q': ['W', 'A', 'S'],\n",
    " 'W': ['Q', 'E', 'A', 'S', 'D'],\n",
    " 'E': ['W', 'R', 'S', 'D', 'F'],\n",
    " 'R': ['E', 'T', 'D', 'F', 'G'],\n",
    " 'T': ['R', 'Y', 'F', 'G', 'H'],\n",
    " 'Y': ['T', 'U', 'G', 'H', 'J'],\n",
    " 'U': ['Y', 'I', 'H', 'J', 'K'],\n",
    " 'I': ['U', 'O', 'J', 'K', 'L'],\n",
    " 'O': ['I', 'P', 'K', 'L'],\n",
    " 'P': ['O', 'L'],\n",
    " 'A': ['Q', 'W', 'S', 'X', 'Z'],\n",
    " 'S': ['E', 'W', 'A', 'D', 'Z', 'X'],\n",
    " 'D': ['R', 'E', 'S', 'F', 'X', 'C'],\n",
    " 'F': ['T', 'R', 'D', 'G', 'C', 'V'],\n",
    " 'G': ['Y', 'T', 'F', 'H', 'V', 'B'],\n",
    " 'H': ['U', 'Y', 'G', 'J', 'B', 'N'],\n",
    " 'J': ['I', 'U', 'H', 'K', 'N', 'M'],\n",
    " 'K': ['O', 'I', 'J', 'L', 'M', ','],\n",
    " 'L': ['I', 'P', 'O', 'K', ',', '.'],\n",
    " 'Z': ['X', 'A', 'S'],\n",
    " 'X': ['S', 'D', 'Z', 'C'],\n",
    " 'C': ['D', 'F', 'X', 'V'],\n",
    " 'V': ['F', 'G', 'C', 'B'],\n",
    " 'B': ['G', 'H', 'V', 'N'],\n",
    " 'N': ['H', 'J', 'B', 'M'],\n",
    " 'M': ['J', 'K', 'N', ','],\n",
    " ',': ['K', 'L', 'M', '.'],\n",
    " '.': ['L', ',']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd83f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two functions necesary for capitalization swap\n",
    "def capitalization_swap(sentence, rate):\n",
    "    #Collect index of each starting letter of the sentence\n",
    "    #Assume sentence starts with a word (which it does in english)\n",
    "    word_start_idx = [0]\n",
    "    for idx, letter in enumerate(sentence):\n",
    "        if letter == \" \":\n",
    "            word_start_idx.append(idx+1)\n",
    "    #Select which words, based on the 'rate' threshold, that are to be altered\n",
    "    selected_word_index = []\n",
    "    for item in word_start_idx:\n",
    "        if random.random() <= rate:\n",
    "            selected_word_index.append(item)\n",
    "    #At the the specific indexes, swap the capitalization of said letter\n",
    "    for idx in selected_word_index:\n",
    "        swapped_cap = sentence[idx].swapcase()\n",
    "        sentence = sentence[:idx] + swapped_cap + sentence[idx+1:]\n",
    "    return sentence\n",
    "\n",
    "#This is the actual function to use on the full text (have the text be a list of strings)\n",
    "def swap_capitalization_corpus(texts, rate):\n",
    "    # Applies the capitalization swap to a list of sentences and returns a new list where the sentences have been altered\n",
    "    altered_corpus = []\n",
    "    for sentence in texts:\n",
    "        #Easy way to skip empty lines =)\n",
    "        if len(sentence) != 0:\n",
    "            altered_corpus.append(capitalization_swap(sentence,rate))\n",
    "    return altered_corpus\n",
    "\n",
    "# The two functions necessary for character swap\n",
    "def character_swap(sentence,rate):\n",
    "    #Swaps a character with the following character\n",
    "    sentence_indexes = list(range(len(sentence)))\n",
    "    chosen_indexes = random.sample(sentence_indexes,int(rate*len(sentence_indexes)))\n",
    "    for idx in chosen_indexes:\n",
    "        #For all except last two indexes, swap two characters at index chosen\n",
    "        if idx <= len(sentence)-3:\n",
    "            sentence = sentence[:idx] + sentence[idx+1] + sentence[idx] + sentence[idx+2:]\n",
    "        #For second last index, no need to do \"rest\" as we are at the end\n",
    "        elif idx == len(sentence)-2:\n",
    "            sentence = sentence[:idx] + sentence[idx+1] + sentence[idx]\n",
    "    return sentence\n",
    "\n",
    "#This is the actual function to use on the full text (have the text be a list of strings)\n",
    "def swap_character_corpus(texts,rate):\n",
    "    # Applies the character swap to a list of sentences, returning the altered list\n",
    "    altered_corpus = []\n",
    "    for sentence in texts:\n",
    "        #Easy way to skip empty lines =)\n",
    "        if len(sentence) != 0:\n",
    "            altered_corpus.append(character_swap(sentence,rate))\n",
    "    return altered_corpus  \n",
    "\n",
    "# The two functions necessary for character removal\n",
    "def character_removal(sentence,rate):\n",
    "    #Swaps a character with the following character\n",
    "    sentence_indexes = list(range(len(sentence)))\n",
    "    chosen_indexes = random.sample(sentence_indexes,int(rate*len(sentence_indexes)))\n",
    "    #Initialize a counter. Every time the sentence is shortened, this counter is incremented. The counter is then subtracted\n",
    "    # from the index, so that the index represents the correct spot for the altered string.\n",
    "    cull_counter = 0\n",
    "    chosen_indexes.sort()\n",
    "    for idx in chosen_indexes:\n",
    "        idx = idx - cull_counter\n",
    "        #Edge case 1: if index is 0, just take entire list minus first entry\n",
    "        if idx == 0:\n",
    "            sentence = sentence[1:]\n",
    "            cull_counter += 1            \n",
    "        #For all except last index, concatinate sentence before idx of removel with after index of removal\n",
    "        elif idx <= len(sentence)-2:\n",
    "            sentence = sentence[:idx] + sentence[idx+1:]\n",
    "            cull_counter += 1\n",
    "        #For second last index, take the entire list minus last entry\n",
    "        elif idx == len(sentence)-1:\n",
    "            sentence = sentence[:-1]\n",
    "    return sentence\n",
    "\n",
    "#This is the actual function to use on the full text (have the text be a list of strings)\n",
    "def remove_character_corpus(texts,rate):\n",
    "    # Applies the character removal to a list of sentences, returning the altered list\n",
    "    altered_corpus = []\n",
    "    for sentence in texts:\n",
    "        # Skip empty lines =) \n",
    "        if len(sentence) != 0:\n",
    "            altered_corpus.append(character_removal(sentence,rate))\n",
    "    return altered_corpus\n",
    "\n",
    "#Code for the character replacement, requires that the dictionary above is loaded in ofc\n",
    "def character_replacement(sentence,rate):\n",
    "    #swaps a char with a neighbor, based on qwerty keyboard\n",
    "    sentence_indexes = list(range(len(sentence)))\n",
    "    chosen_indexes = random.sample(sentence_indexes,int(rate*len(sentence_indexes)))\n",
    "    for idx in chosen_indexes:\n",
    "        current_letter = sentence[idx]\n",
    "        if current_letter in approx_dict_lower:\n",
    "            #selects one of the neighbors\n",
    "            chosen_letter = random.sample(approx_dict_lower[current_letter],1)\n",
    "            actual_letter = chosen_letter[0]\n",
    "            sentence = sentence[:idx] + actual_letter + sentence[idx+1:]\n",
    "        elif current_letter in approx_dict_upper:\n",
    "            chosen_letter = random.sample(approx_dict_upper[current_letter],1)\n",
    "            actual_letter = chosen_letter[0]\n",
    "            sentence = sentence[:idx] + actual_letter + sentence[idx+1:]\n",
    "        else:\n",
    "            continue\n",
    "    return sentence\n",
    "\n",
    "#Self explanatory at this point\n",
    "def character_replacement_corpus(texts,rate):\n",
    "    #applies the char replacement to list of sentences, returning altered list\n",
    "    altered_corpus = []\n",
    "    for sentence in texts:\n",
    "        # Skip empty lines =) \n",
    "        if len(sentence) != 0:\n",
    "            altered_corpus.append(character_replacement(sentence,rate))\n",
    "    return altered_corpus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882edad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"str\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/florentinafabregas/Documents/ITU/NLP -- PROJECT/NLP/Adding_noise_clean.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m input_data \u001b[39m=\u001b[39m read_file_content(input_file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Inject noise\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m altered_data \u001b[39m=\u001b[39m swap_capitalization_corpus(input_data, rate)  \u001b[39m# Example noise function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Write altered data to output file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m write_file_content(output_file, altered_data)\n",
      "\u001b[1;32m/Users/florentinafabregas/Documents/ITU/NLP -- PROJECT/NLP/Adding_noise_clean.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m texts:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m#Easy way to skip empty lines =)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sentence) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         altered_corpus\u001b[39m.\u001b[39mappend(capitalization_swap(sentence,rate))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m altered_corpus\n",
      "\u001b[1;32m/Users/florentinafabregas/Documents/ITU/NLP -- PROJECT/NLP/Adding_noise_clean.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m selected_word_index:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     swapped_cap \u001b[39m=\u001b[39m sentence[idx]\u001b[39m.\u001b[39mswapcase()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     sentence \u001b[39m=\u001b[39m sentence[:idx] \u001b[39m+\u001b[39m swapped_cap \u001b[39m+\u001b[39m sentence[idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/florentinafabregas/Documents/ITU/NLP%20--%20PROJECT/NLP/Adding_noise_clean.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sentence\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"str\") to tuple"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#Some cleaning of lines, removing empty lines.\n",
    "def read_file_content(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        cleansed_lines = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                parts = line.split()\n",
    "                word = parts[0]\n",
    "                tags = parts[1:]\n",
    "                cleansed_lines.append((word, *tags))\n",
    "        return cleansed_lines\n",
    "\n",
    "# Output function to write the altered data back to a file\n",
    "def write_file_content(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for word, *tags in data:\n",
    "            line = ' '.join([word, *tags])\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "# Rest of your code for noise injection functions...\n",
    "\n",
    "# Example usage:\n",
    "input_file = 'data/test.txt'\n",
    "output_file = 'data/swap_cap_0.5.txt'\n",
    "rate = 0.5  # Example noise rate\n",
    "\n",
    "# Read input data\n",
    "input_data = read_file_content(input_file)\n",
    "\n",
    "# Inject noise\n",
    "altered_data = swap_capitalization_corpus(input_data, rate)  # Example noise function\n",
    "\n",
    "# Write altered data to output file\n",
    "write_file_content(output_file, altered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2479ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Load input file\n",
    "with open('data/test.txt', 'r', encoding='utf-8') as file:\n",
    "    input_data = file.read().splitlines()\n",
    "\n",
    "# Apply noise injection functions\n",
    "altered_data = []\n",
    "altered_data.append(swap_capitalization_corpus(input_data, 0.5))\n",
    "altered_data.append(swap_character_corpus(input_data, 0.1))\n",
    "altered_data.append(remove_character_corpus(input_data, 0.1))\n",
    "altered_data.append(character_replacement_corpus(input_data, 0.1))\n",
    "\n",
    "# Output altered data\n",
    "for i, data in enumerate(altered_data):\n",
    "    with open(f'data/output_{i+1}.txt', 'w', encoding='utf-8') as file:\n",
    "        for sentence in data:\n",
    "            file.write(sentence + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410baea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
